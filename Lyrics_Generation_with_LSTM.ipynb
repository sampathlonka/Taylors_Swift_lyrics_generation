{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EdQM2CYHciwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b120b3-9d5f-4ab8-ed75-caef3d3965a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#working directory\n",
        "%cd '/content/drive/MyDrive/lyrics_generator/'"
      ],
      "metadata": {
        "id": "k-QpBK88dVPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c556da86-6494-410f-b930-64756bec751e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/lyrics_generator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction"
      ],
      "metadata": {
        "id": "2gFEYaxF2A-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this article, we delve into the fascinating world of lyrics generation using Long Short-Term Memory (LSTM) modeling techniques, focusing specifically on [Taylor Swift's](https://www.kaggle.com/datasets/ishikajohari/taylor-swift-all-lyrics-30-albums) lyrical repertoire.\n",
        "\n",
        "This dataset has the lyrics of almost all, if not all, of Taylor Swift's songs from 46 albums. The lyrics are in a textual format (.txt) for maximum user flexibility. Additionally, the dataset includes cover art for each of these albums.\n",
        "\n",
        "LSTM, a type of recurrent neural network (RNN), has gained immense popularity in natural language processing tasks, including text generation. It possesses a unique ability to capture and learn patterns in sequential data, making it an ideal candidate for creating realistic and artistically appealing lyrics.\n",
        "\n",
        "By harnessing the power of LSTM, we can embark on a journey to understand the underlying structure and themes of Taylor Swift's lyrics. Our goal is to not only generate lyrics that mimic her distinctive style but also gain insights into her creative process and storytelling techniques."
      ],
      "metadata": {
        "id": "59umHMXm09Wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load necessary modules\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "h0r-hS2zc7BS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    punctuation_pad = '!?.,:-;'\n",
        "    # end of verse tokenization\n",
        "    content = re.sub(r'\\n\\n',r\"<EOV>\", text)\n",
        "    # end of sentence\n",
        "    content = re.sub(r'\\n', r\"<EOS>\", content)\n",
        "    content = re.sub(r'\\|.*?\\|','',content)\n",
        "    content = content.translate(str.maketrans({key: ' {0} '.format(key) for key in punctuation_pad}))\n",
        "    content = re.sub(' +', ' ', content)\n",
        "    content = re.split(r'(<EOS>)|(<EOV>)',content)\n",
        "    updated_content = ['' if element is None else element for element in content]\n",
        "    return ' '.join(updated_content)"
      ],
      "metadata": {
        "id": "I-4HaSvqd_qU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Train-Test Split\n",
        "lyrics_dir = \"../lyrics_generator/Data/\"\n",
        "# all lyrics together as list\n",
        "all_lyrics = []\n",
        "for filename in os.listdir(lyrics_dir):\n",
        "    with open(os.path.join(lyrics_dir, filename), \"r\") as f:\n",
        "        lyrics = f.read()\n",
        "        process_lyrics = preprocess(lyrics)\n",
        "        all_lyrics.append(process_lyrics)"
      ],
      "metadata": {
        "id": "bu2BlUAfedWy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_lyrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG72yOXVIwjg",
        "outputId": "1259eb37-377a-4848-d585-bc9ac84777ea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform train-test split\n",
        "train_lyrics, test_lyrics = train_test_split(all_lyrics, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TxXi4ic_eR_x"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lyrics[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "B-Ho5i2Kpdpn",
        "outputId": "0329abdd-5bd7-4291-a6d7-a1b5c56dbbd5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Intro  <EOV> Verse 1 <EOS>  Once upon a time , a few mistakes ago <EOS>  I was in your sights , you got me alone <EOS>  You found me , you found me <EOS>  You found me - e - e - e - e <EOS>  I guess you didn't care , and I guess I liked that <EOS>  And when I fell hard , you took a step back <EOS>  Without me , without me <EOS>  Without me - e - e - e - e <EOS>  Pre - Chorus <EOS>  And he's long gone when he's next to me <EOS>  And I realize the blame is on me  <EOV> Chorus <EOS>  'Cause I knew you were trouble when you walked in <EOS>  So shame on me now <EOS>  Flew me to places I'd never been <EOS>  'Til you put me down , oh <EOS>  I knew you were trouble when you walked in <EOS>  So shame on me now <EOS>  Flew me to places I'd never been <EOS>  Now , I'm lying on the cold , hard ground  <EOV> Post - Chorus <EOS>  Oh , oh - oh <EOS>  Trouble , trouble , trouble <EOS>  Oh , oh - oh <EOS>  Trouble , trouble , trouble  <EOV> Verse 2 <EOS>  No apologies , he'll never see you cry <EOS>  Pretends he doesn't know that he's the reason why <EOS>  You're drowning , you're drowning <EOS>  You're drowning - ing - ing - ing - ing <EOS>  And I heard you moved on from whispers on the street <EOS>  A new notch in your belt is all I'll ever be <EOS>  And now , I see , now , I see <EOS>  Now , I see - e - e - e - e <EOS>  You might also likePre - Chorus <EOS>  He was long gone when he met me <EOS>  And I realize the joke is on me , yeah  <EOV> Chorus <EOS>  I knew you were trouble when you walked in Oh <EOS>  So shame on me now <EOS>  Flew me to places I'd never been <EOS>  'Til you put me down , oh <EOS>  I knew you were trouble when you walked in <EOS>  So shame on me now <EOS>  Flew me to places I'd never been Yeah <EOS>  Now , I'm lying on the cold , hard ground  <EOV> Post - Chorus <EOS>  Oh , oh - oh <EOS>  Trouble , trouble , trouble Yeah , trouble <EOS>  Oh , oh - oh <EOS>  Trouble , trouble , trouble  <EOV> Bridge <EOS>  And the saddest fear <EOS>  Comes creeping in <EOS>  That you never loved me <EOS>  Or her , or anyone , or anything , yeah <EOS>  Chorus <EOS>  I knew you were trouble when you walked in <EOS>  So shame on me now <EOS>  Flew me to places I'd never been Never been <EOS>  'Til you put me down , oh <EOS>  I knew you were trouble when you walked in Knew it right there <EOS>  So shame on me now Knew it right there <EOS>  Flew me to places I'd never been Ooh <EOS>  Now , I'm lying on the cold , hard ground  <EOV> Post - Chorus <EOS>  Oh , oh - oh <EOS>  Trouble , trouble , trouble Oh <EOS>  Oh , oh - oh <EOS>  Trouble , trouble , trouble <EOS>  I knew you were trouble when you walked in <EOS>  Trouble , trouble , trouble <EOS>  I knew you were trouble when you walked in <EOS>  Trouble , trouble , trouble <EOS>  Outro\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modules related to generating the dataset and training model\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "M6ZgRpanev9N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LyricsDataset():\n",
        "    def __init__(self,text, sequence_length=4):\n",
        "        self.text = text\n",
        "        self.sequence_length = sequence_length\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "        # add unknown tokens to the word to index\n",
        "        self.word_to_index['<UNK>'] = len(self.word_to_index)\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "        \n",
        "    def load_words(self):\n",
        "        total_words = []\n",
        "        text = self.text\n",
        "        for i in range(len(text)):\n",
        "            for sentence in text[i].splitlines():\n",
        "                for word in sentence.split(' '):\n",
        "                    total_words.append(word)\n",
        "        word_counts = Counter(total_words)\n",
        "        filtered_words = [word if word_counts[word] >= 1  else '<UNK>' for word in total_words]\n",
        "        return filtered_words        \n",
        "        \n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        word_counts['<UNK>'] = 0  # Add the <UNK> token with count 0\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.sequence_length\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        sequence = torch.tensor(self.words_indexes[index:index+self.sequence_length])\n",
        "        sequence[sequence >= len(self.uniq_words)] = self.word_to_index['<UNK>']\n",
        "        target = torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1])\n",
        "        target[target >= len(self.uniq_words)] = self.word_to_index['<UNK>']\n",
        "        return torch.tensor(sequence), torch.tensor(target)"
      ],
      "metadata": {
        "id": "SuE10ycje9dF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create LyricsDataset\n",
        "seq_length = 6\n",
        "train_data = LyricsDataset(train_lyrics, sequence_length=seq_length)\n",
        "test_data = LyricsDataset(test_lyrics, sequence_length=seq_length)"
      ],
      "metadata": {
        "id": "5AMYwrfFf5ec"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_lyrics = LyricsDataset(all_lyrics, sequence_length=seq_length)"
      ],
      "metadata": {
        "id": "sD0xkACkn5ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "vmHOTVahgISn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device =torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "lzfaDq0zgP-I"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#develop LSTM model\n",
        "class LSTMmodel(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(LSTMmodel, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "        return logits, state\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
      ],
      "metadata": {
        "id": "xOmJjxeggaEO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMmodel(train_data)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "zfpw-EU8gpAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457ccc4b-bc7b-45a8-8df2-4fef480c3a91"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMmodel(\n",
              "  (embedding): Embedding(11100, 128)\n",
              "  (lstm): LSTM(128, 128, num_layers=3, dropout=0.2)\n",
              "  (fc): Linear(in_features=128, out_features=11100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "gHTwJpcZguZ-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader, model):\n",
        "    val_loss = 0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for batch, (x, y) in tqdm(enumerate(dataloader)):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            # Initialize states for each batch\n",
        "            state_h, state_c = model.init_state(x.size(1))  \n",
        "            state_h = state_h.to(device)\n",
        "            state_c = state_c.to(device)\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "            val_loss += loss.item()\n",
        "            count += 1\n",
        "    avg_val_loss = val_loss / count\n",
        "    #print({'loss': avg_val_loss})\n",
        "    return avg_val_loss"
      ],
      "metadata": {
        "id": "6pRORTszg8-1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train( model, dataloader,test_loader,epochs=10):\n",
        "    loss = 0\n",
        "    for epoch in range(epochs):\n",
        "      model.train()\n",
        "      state_h, state_c = model.init_state(seq_length)\n",
        "      state_h = torch.tensor(state_h).to(device)\n",
        "      state_c = torch.tensor(state_c).to(device)\n",
        "      count = 0\n",
        "      for batch, (x, y) in tqdm(enumerate(dataloader)):\n",
        "          optimizer.zero_grad()\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "          y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "          loss = criterion(y_pred.transpose(1, 2), y)\n",
        "          state_h = state_h.detach()\n",
        "          state_c = state_c.detach()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          loss += loss.item()\n",
        "          count += 1\n",
        "      avg_loss = loss.item()/count\n",
        "      # valuation\n",
        "      model.eval()\n",
        "      val_loss = evaluate(test_loader,model)\n",
        "      print(f\"epoch: {epoch}, train loss: {avg_loss}, val loss: {avg_loss}\")"
      ],
      "metadata": {
        "id": "2X0spqiUhCJT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model,train_loader,test_loader)"
      ],
      "metadata": {
        "id": "s4xO-QJKh8Ik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d513a78-01a3-4ed0-a878-fe1f9645419b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-33f77bcd18c4>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  state_h = torch.tensor(state_h).to(device)\n",
            "<ipython-input-39-33f77bcd18c4>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  state_c = torch.tensor(state_c).to(device)\n",
            "0it [00:00, ?it/s]<ipython-input-30-5e00c0fa84c2>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(sequence), torch.tensor(target)\n",
            "127504it [07:16, 292.12it/s]\n",
            "30429it [00:31, 965.91it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, train loss: 7.265320026466158e-05, val loss: 7.265320026466158e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127504it [07:11, 295.46it/s]\n",
            "30429it [00:32, 945.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, train loss: 6.882309509738803e-05, val loss: 6.882309509738803e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127504it [07:12, 294.64it/s]\n",
            "30429it [00:31, 973.64it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2, train loss: 8.192787446854838e-05, val loss: 8.192787446854838e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127504it [07:12, 294.80it/s]\n",
            "30429it [00:33, 911.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 3, train loss: 7.29978735286269e-05, val loss: 7.29978735286269e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127504it [07:16, 291.81it/s]\n",
            "30429it [00:31, 966.05it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 4, train loss: 7.762153050818426e-05, val loss: 7.762153050818426e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127504it [07:16, 292.09it/s]\n",
            "30429it [00:31, 962.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 5, train loss: 8.1432547828367e-05, val loss: 8.1432547828367e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127504it [07:11, 295.15it/s]\n",
            "30429it [00:31, 977.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 6, train loss: 9.182626950664523e-05, val loss: 9.182626950664523e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127504it [07:10, 296.49it/s]\n",
            "30429it [00:31, 961.54it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 7, train loss: 8.408507793367635e-05, val loss: 8.408507793367635e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127504it [07:09, 296.83it/s]\n",
            "30429it [00:31, 981.14it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 8, train loss: 6.881857744078817e-05, val loss: 6.881857744078817e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127504it [07:08, 297.58it/s]\n",
            "30429it [00:30, 982.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 9, train loss: 6.083664862390653e-05, val loss: 6.083664862390653e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the model for future use"
      ],
      "metadata": {
        "id": "ZEVcsH8iNddb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Assuming you have defined and trained your LSTM model\n",
        "lstm_model = LSTMmodel(train_data)\n",
        "\n",
        "# Specify the file path to save the model\n",
        "model_path = '/content/drive/MyDrive/lyrics_generator/models/lstm_modelv2.pth'\n",
        "\n",
        "# Save the model\n",
        "torch.save(lstm_model.state_dict(), model_path)\n"
      ],
      "metadata": {
        "id": "KlGrAHi4NQRM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model for evaluation"
      ],
      "metadata": {
        "id": "YohuUBs-Nifd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "065kBldVpSFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path of the saved model\n",
        "model_path = '/content/drive/MyDrive/lyrics_generator/models/lstm_modelv2.pth'\n",
        "\n",
        "# Load the model\n",
        "model = LSTMmodel(train_data)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device)\n",
        "model.eval()  # Set the model to evaluation mode\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Jso7vENh-r",
        "outputId": "1cf9e2b7-5bba-4556-a807-0a0bf143bf66"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMmodel(\n",
              "  (embedding): Embedding(11100, 128)\n",
              "  (lstm): LSTM(128, 128, num_layers=3, dropout=0.2)\n",
              "  (fc): Linear(in_features=128, out_features=11100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "vy8nQDpMpxuQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(train_data, model, prompt, next_words=400):\n",
        "    model.eval()\n",
        "    prompt = prompt.replace('\\n', ' <EOS>')\n",
        "    words = prompt.split(' ')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        state_h, state_c = model.init_state(len(words))\n",
        "        state_h, state_c = state_h.to(device), state_c.to(device)\n",
        "\n",
        "        for i in range(next_words):\n",
        "            if words[i] not in train_data.word_to_index:\n",
        "                words[i] = '<UNK>'\n",
        "\n",
        "            x = torch.tensor([[train_data.word_to_index[w] for w in words[i:]]]).to(device)\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            last_word_logits = y_pred[0][-1]\n",
        "            p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "\n",
        "            try:\n",
        "                word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "                words.append(train_data.index_to_word[word_index])\n",
        "            except KeyError:\n",
        "                words.append('<UNK>')\n",
        "\n",
        "        generated_text = ' '.join(words)\n",
        "        generated_text += prompt\n",
        "        generated_text = adjust_text_format(generated_text)\n",
        "        generated_text = adjust_verses(generated_text)\n",
        "        return generated_text\n",
        "\n",
        "\n",
        "def adjust_text_format(text):\n",
        "    text = text.replace('<EOV>', '\\n\\n')\n",
        "    text = text.replace('<EOS>', '\\n')\n",
        "    lines = text.splitlines()\n",
        "    formatted_lyrics = []\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        if len(line) > 10:\n",
        "            formatted_lines = split_line(line, max_words_per_line=random.randint(3, 6))\n",
        "            formatted_lyrics.extend(formatted_lines)\n",
        "        else:\n",
        "            formatted_lyrics.append(line)\n",
        "\n",
        "        if (i + 1) % 5 == 0:\n",
        "            formatted_lyrics.append('\\n\\n')\n",
        "\n",
        "    formatted_lyrics = '\\n'.join(formatted_lyrics)\n",
        "    return formatted_lyrics\n",
        "\n",
        "\n",
        "def split_line(line, max_words_per_line):\n",
        "    words = line.split()\n",
        "    lines = []\n",
        "    current_line = []\n",
        "\n",
        "    for word in words:\n",
        "        if len(current_line) < max_words_per_line:\n",
        "            current_line.append(word)\n",
        "        else:\n",
        "            lines.append(' '.join(current_line))\n",
        "            current_line = [word]\n",
        "\n",
        "    if current_line:\n",
        "        lines.append(' '.join(current_line))\n",
        "\n",
        "    return lines\n",
        "\n",
        "\n",
        "def adjust_verses(text):\n",
        "    lines = text.splitlines()\n",
        "    formatted_lyrics = ''\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        formatted_lyrics += '\\n' + line\n",
        "        if (i + 1) % 5 == 0:\n",
        "            formatted_lyrics += '\\n\\n'\n",
        "\n",
        "    return formatted_lyrics\n"
      ],
      "metadata": {
        "id": "zM_1FaotkVWh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Like the war of words I shouted\\n in my sleep And you passed right by\\n\"\n",
        "generated_text = predict(train_data, model, prompt)"
      ],
      "metadata": {
        "id": "6EDWzOH66X6_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "id": "4sv8h1oi30zK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a03825b-a8b8-4ad3-960e-fe3f75dcfe96"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Like the war of words I\n",
            "shouted\n",
            "in my sleep And\n",
            "you passed right by\n",
            "curl Sleepwalking Steve\n",
            "\n",
            "\n",
            "Off lupines sharply\n",
            "scuffling amplifie Briskly\n",
            "Titans pointed pressed\n",
            "Breathing speechesI careif\n",
            "mend boiled It\n",
            "\n",
            "\n",
            "Emperor Promise gowns\n",
            "sparkin' spending Cars\n",
            "Representing soundtrack 238\n",
            "paced Comin' meam\n",
            "R Be Grab\n",
            "\n",
            "\n",
            "week goodbye HUNDRED\n",
            "turns estates owest\n",
            "prison Wait judges\n",
            "bags JAY bear\n",
            "scholar backseat Dawn\n",
            "\n",
            "\n",
            "fight shewed quarrelling\n",
            "white commended Honester\n",
            "home spoon White\n",
            "461 cuts Thick\n",
            "1966 pliant Woman\n",
            "\n",
            "\n",
            "\"awesome\" creepin' Prohibido\n",
            "Vert excuse need\n",
            "Whose omni gleam\n",
            "Lookin likeEmbed hug\n",
            "Sollicitavit fact wait\n",
            "\n",
            "\n",
            "followeth Entreated mornin'\n",
            "favourable wearing Chicks\n",
            "your pleasanter hurt\n",
            "four Youth keeper\n",
            "Tokens Stock faking\n",
            "\n",
            "\n",
            "E Tying staircase\n",
            "suspected it'slike rule\n",
            "Dan guilty ruled\n",
            "Blonde empire 24\n",
            "broom 111 fingers\n",
            "\n",
            "\n",
            "Yellow bump band\n",
            "Clandestino boar's Lucilius\n",
            "Mixt conduit eating\n",
            "hussye worst Monuments\n",
            "freckle stale Tove\n",
            "\n",
            "\n",
            "chanced bong Proper\n",
            "Agamemnon metheglin attack'd\n",
            "seeming ContributorsThe Jupiter\n",
            "Unhappy matters Euripides\n",
            "TRUE apologies rub\n",
            "\n",
            "\n",
            "appeared advocate Proclamations\n",
            "saving Frog Ha\n",
            "choicest Beautiful\" arrow\n",
            "paper broke goin'\n",
            "Solicitor girt Olivia\n",
            "\n",
            "\n",
            "Drank KO 20\n",
            "She'll elegies Piper\n",
            "Reverence lover's someone's\n",
            "expose Idler Plotted\n",
            "Affection forbid hold\n",
            "\n",
            "\n",
            "289 wicked all's\n",
            "Dum Oxen sirrah\n",
            "HUNDRED Hoes Cabello\n",
            "advocates Greatest sparkle\n",
            "KO Babylon server\n",
            "\n",
            "\n",
            "assume working unglued\n",
            "theres approve Fight\n",
            "advis'd Ask Turn'd\n",
            "Wreck Fiji ushers\n",
            "nothing \"Trimalchio's 304\n",
            "\n",
            "\n",
            "luxury worthy aviary\n",
            "Net thinkin' spoils\n",
            "CorneliaStreet\" Believe Tarentum\n",
            "Troy He Fashioned\n",
            "rust Gary lagg\n",
            "\n",
            "\n",
            "Necessity magpye finding\n",
            "Bathed \"Say Poor\n",
            "Drink sett Come\n",
            "stuff'd comfortable miss'd\n",
            "aversion dried shamms\n",
            "\n",
            "\n",
            "Saturnals Snow wonderin'\n",
            "Echoes farrowed assa\n",
            "Nonchalant \"Starboy\" Crack\n",
            "lash puddings Thrive\n",
            "Publius Dogs easier\n",
            "\n",
            "\n",
            "belly 335 neighbor\n",
            "Conspicata Elisha rangers\n",
            "learn'd grows Liked\n",
            "90 observing ordering\n",
            "lookers Cara relate\n",
            "\n",
            "\n",
            "explanations muse Midnights\n",
            "building torn Castle\n",
            "drove too\" eight\n",
            "desperately 1988 Trends\n",
            "\"Fausie bruise Least\n",
            "\n",
            "\n",
            "musick time\" goddamn\n",
            "pragmatism culver jailer\n",
            "sinkin' Reversion fond\n",
            "324 blush favour\n",
            "78 ContributorsSatyricon 'bout\n",
            "\n",
            "\n",
            "Aratus DJ boar\n",
            "thy lucky attitude\n",
            "Confession manEmbed toucht\n",
            "still 75 Incontinently\n",
            "Wheel quest rods\n",
            "\n",
            "\n",
            "jealousy Friend 443\n",
            "upon't shovin' Wildest\n",
            "119 Deserved door\n",
            "understudy \"Meet other\n",
            "leap Dangerous brag\n",
            "\n",
            "\n",
            "screen's presented Tarnished\n",
            "142 broken Laughter\n",
            "Melissa Christina recusantem\n",
            "supper Contubernali still\n",
            "tests exile LyricsCouldnt\n",
            "\n",
            "\n",
            "unpunisht strict vasculo\n",
            "risu knife Makin'\n",
            "shore hangings beauty\n",
            "Better Shouting doctor\n",
            "hopeful dust pomegranate\n",
            "\n",
            "\n",
            "Years There'll Drunkenness\n",
            "how God Kiiara\n",
            "Kai puto aid\n",
            "taurum suspected wou'd\n",
            "Lylli Ocean Colors\n",
            "\n",
            "\n",
            "answer'd reverend execution\n",
            "madness Joke scholars\n",
            "insincerity Pack battered\n",
            "swam Riddim Sprinkle\n",
            "pan fir'd relieved\n",
            "\n",
            "\n",
            "Havana disdainfully beans\n",
            "tothe Given Van\n",
            "matter Ugly broaches\n",
            "crying roller Blonde\n",
            "saltbox Guetta spread\n",
            "\n",
            "\n",
            "40 Whereupon rascals\n",
            "crashed pumpkin balance\n",
            "codicilLike the war\n",
            "of words I\n",
            "shouted\n",
            "\n",
            "\n",
            "in my sleep\n",
            "And you passed\n",
            "right by\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = {'original_lyrics':[],'gen_lyrics':[]}\n",
        "for txt in random.sample(train_lyrics, k=10):\n",
        "  txt_split = txt.split('<EOS>')\n",
        "  prompt = str('<EOS>'.join(txt_split[:3]))\n",
        "  #print(prompt)\n",
        "  gen_text = predict(train_data,model,prompt)\n",
        "  df['original_lyrics'].append(txt)\n",
        "  df['gen_lyrics'].append(gen_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMb_WtyqTUAN",
        "outputId": "491298a9-58c2-476b-ad5a-f8e61f595300"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 ContributorYou Cant Dance With Me LyricsCouldnt get a job , probably have to be a grad student <EOS>  All this college shit has got my swag ruin <EOS>  People think I sound like Eminem \n",
            "Verse 1 <EOS>  Friends break up , friends get married <EOS>  Strangers get born , strangers get buried \n",
            "Trke eviri <EOS>  Once upon a time , a few mistakes ago <EOS>  I was in your sights , you got me alone \n",
            "Intro <EOS>  I remember  <EOV> Verse 1 <EOS>  Good girl , sad boy \n",
            "Verse 1 <EOS>  When the dinner is cold and the chatter gets old <EOS>  You ask for the tab \n",
            "Verse 1 <EOS>  Fatefully <EOS>  I tried to pick my battles 'til the battle picked me \n",
            "Verse 1 <EOS>  Keep your helmet , keep your life , son <EOS>  Just a flesh wound , here's your rifle \n",
            "Intro <EOS>  Meet me at midnight  <EOV> Verse 1 <EOS>  Staring at the ceiling with you \n",
            "Verse 1 <EOS>  I took a chance , I took a shot <EOS>  And you might think I'm bulletproof , but I'm not \n",
            "Verse 1 : Taylor Swift <EOS>  Break my soul in two looking for you <EOS>  But you're right here \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6srsJu7MKJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gen = pd.DataFrame(df)\n",
        "df_gen"
      ],
      "metadata": {
        "id": "NfaSBMI9UfZa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "4871ec81-e53e-4eb1-f835-0ff961ca66e2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     original_lyrics  \\\n",
              "0  1 ContributorYou Cant Dance With Me LyricsCoul...   \n",
              "1  Verse 1 <EOS>  Friends break up , friends get ...   \n",
              "2  Trke eviri <EOS>  Once upon a time , a few mis...   \n",
              "3  Intro <EOS>  I remember  <EOV> Verse 1 <EOS>  ...   \n",
              "4  Verse 1 <EOS>  When the dinner is cold and the...   \n",
              "5  Verse 1 <EOS>  Fatefully <EOS>  I tried to pic...   \n",
              "6  Verse 1 <EOS>  Keep your helmet , keep your li...   \n",
              "7  Intro <EOS>  Meet me at midnight  <EOV> Verse ...   \n",
              "8  Verse 1 <EOS>  I took a chance , I took a shot...   \n",
              "9  Verse 1 : Taylor Swift <EOS>  Break my soul in...   \n",
              "\n",
              "                                          gen_lyrics  \n",
              "0  \\n1 ContributorYou Cant\\nDance With Me\\nLyrics...  \n",
              "1  \\nVerse 1 \\nFriends break up\\n, friends get\\nm...  \n",
              "2  \\nTrke eviri\\nOnce upon a time\\n, a few mistak...  \n",
              "3  \\nIntro \\nI remember\\n\\n Verse 1 \\nGood girl ,...  \n",
              "4  \\nVerse 1 \\nWhen the dinner is\\ncold and the c...  \n",
              "5  \\nVerse 1 \\nFatefully\\nI tried to pick my\\nbat...  \n",
              "6  \\nVerse 1 \\nKeep your helmet , keep\\nyour life...  \n",
              "7  \\nIntro \\nMeet me at midnight\\n\\n Verse 1 \\nSt...  \n",
              "8  \\nVerse 1 \\nI took a\\nchance , I\\ntook a shot\\...  \n",
              "9  \\nVerse 1 : Taylor\\nSwift\\nBreak my soul\\nin t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70ebe6ee-dbd4-4046-aebd-e8f4eca73af2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_lyrics</th>\n",
              "      <th>gen_lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1 ContributorYou Cant Dance With Me LyricsCoul...</td>\n",
              "      <td>\\n1 ContributorYou Cant\\nDance With Me\\nLyrics...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Verse 1 &lt;EOS&gt;  Friends break up , friends get ...</td>\n",
              "      <td>\\nVerse 1 \\nFriends break up\\n, friends get\\nm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trke eviri &lt;EOS&gt;  Once upon a time , a few mis...</td>\n",
              "      <td>\\nTrke eviri\\nOnce upon a time\\n, a few mistak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Intro &lt;EOS&gt;  I remember  &lt;EOV&gt; Verse 1 &lt;EOS&gt;  ...</td>\n",
              "      <td>\\nIntro \\nI remember\\n\\n Verse 1 \\nGood girl ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Verse 1 &lt;EOS&gt;  When the dinner is cold and the...</td>\n",
              "      <td>\\nVerse 1 \\nWhen the dinner is\\ncold and the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Verse 1 &lt;EOS&gt;  Fatefully &lt;EOS&gt;  I tried to pic...</td>\n",
              "      <td>\\nVerse 1 \\nFatefully\\nI tried to pick my\\nbat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Verse 1 &lt;EOS&gt;  Keep your helmet , keep your li...</td>\n",
              "      <td>\\nVerse 1 \\nKeep your helmet , keep\\nyour life...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Intro &lt;EOS&gt;  Meet me at midnight  &lt;EOV&gt; Verse ...</td>\n",
              "      <td>\\nIntro \\nMeet me at midnight\\n\\n Verse 1 \\nSt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Verse 1 &lt;EOS&gt;  I took a chance , I took a shot...</td>\n",
              "      <td>\\nVerse 1 \\nI took a\\nchance , I\\ntook a shot\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Verse 1 : Taylor Swift &lt;EOS&gt;  Break my soul in...</td>\n",
              "      <td>\\nVerse 1 : Taylor\\nSwift\\nBreak my soul\\nin t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70ebe6ee-dbd4-4046-aebd-e8f4eca73af2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70ebe6ee-dbd4-4046-aebd-e8f4eca73af2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70ebe6ee-dbd4-4046-aebd-e8f4eca73af2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using BLEU score to compare the real sentences with the generated ones\n",
        "import statistics\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "id": "0VeqRWGlMS0B"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse(text):\n",
        "  content = re.sub(r'<EOS>',' ',text)\n",
        "  content = re.sub(r'<EOS>',' ',content)\n",
        "  content = re.sub(r'\\n',' ', content)\n",
        "  return content\n",
        "\n"
      ],
      "metadata": {
        "id": "rHgxWnCEMWRd"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gen_clean = df_gen.applymap(reverse)"
      ],
      "metadata": {
        "id": "Pm1f4eBtO6Uo"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores=[]\n",
        "\n",
        "for i in range(df_gen_clean.shape[0]):\n",
        "  reference = df_gen_clean['original_lyrics'][i]\n",
        "  candidate = df_gen_clean['gen_lyrics'][i]\n",
        "  scores.append(sentence_bleu(reference, candidate))\n",
        "\n",
        "statistics.mean(scores)"
      ],
      "metadata": {
        "id": "JJzxPhNQ43Xm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db53af4-07e9-446a-b271-88b66f68da4c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.36959445327723e-232"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusions\n",
        "\n",
        "- We haven't used any word embeddings.\n",
        "- If we use embeddings like Glove or BERT, the perfomance can be improved.\n",
        "- In conclusion, improving the BLEU score on the Taylor Swift Lyrics dataset using LSTM models requires exploring different model architectures, optimizing hyperparameters, augmenting the data, leveraging ensemble methods, experimenting with alternative sequence generation approaches, and considering fine-tuning of pre-trained models. \n",
        "- These strategies can collectively contribute to enhancing the model's understanding of the lyrics and generating more accurate and coherent outputs."
      ],
      "metadata": {
        "id": "2RwapXypPKUi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_VPGnz0vMt_P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}